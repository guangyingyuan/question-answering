## Last Run

*URL:* http://localhost:8080/query

*Query:* Can Watson NLP run as containers on multi cloud environments?

*Answer:* Yes, Watson NLP can run as containers on multi cloud environments.

*Duration in Milliseconds:* 5017


### Watson Discovery

*Results (matching):* 7

*Results (returned):* 7

*Results (max):* 30

*Characters per Passage:* 1000

*Find Answers:* false

*Duration in Milliseconds:* 673

*Result 1 chunckid or document_id:* 1.article/running-and-deploying-ibm-watson-nlp-containers/

<details><summary>Result 1</summary>This post describes different options how to run and deploy Watson NLP. To set some context, check out the landing page IBM Watson NLP Library for Embed. The Watson NLP containers can be run on different container platforms, they provide REST and gRCP interfaces, they can be extended with custom models and they can easily be embedded in solutions. While this offering is new, the underlaying functionality has been used and optimized for a long time in IBM offerings like the IBM Watson Assistant and NLU (Natural Language Understanding) SaaS services and IBM Cloud Pak for Data. Via kubectl or oc Kubernetes resources can be deployed. The Watson NLP pod contains the NLP runtime container and potentially multiple init containers. Each init container contains either predefined or custom models.</details>

*Result 2 chunckid or document_id:* 0.article/running-and-deploying-ibm-watson-nlp-containers/

<details><summary>Result 2</summary>IBM Watson NLP (Natural Language Understanding) and Watson Speech containers can be run locally, on-premises or Kubernetes and OpenShift clusters.</details>

*Result 3 chunckid or document_id:* 0.en/about/press-releases/ibm-closes-landmark-acquisition-red-hat-34-billion-defines-open-hybrid-cloud-future

<details><summary>Result 3</summary>Generally available today, the AI libraries were developed in IBM Research and designed to provide Independent Software Vendors (ISVs) across industries an easily scalable way to build natural language processing, speech to text, and text to speech capabilities into applications across any hybrid, multi cloud environment.</details>


### Re-Ranker

*ID:* ColBERTReranker

*Model:* /store/checkpoints/drdecr/DrDecr.dnn

*Duration in Milliseconds:* 783

*Input Documents Max:* 20

*Input Documents Actual:* 7

*Ouput Documents Actual:* 6

*Result 1 chunckid or document_id:* 0.article/running-and-deploying-ibm-watson-nlp-containers/

<details><summary>Result 1</summary>Running and Deploying IBM Watson NLP Containers. IBM Watson NLP (Natural Language Understanding) and Watson Speech containers can be run locally, on-premises or Kubernetes and OpenShift clusters.</details>

*Result 2 chunckid or document_id:* 1.article/running-and-deploying-ibm-watson-nlp-containers/

<details><summary>Result 2</summary>Running and Deploying IBM Watson NLP Containers. This post describes different options how to run and deploy Watson NLP. To set some context, check out the landing page IBM Watson NLP Library for Embed. The Watson NLP containers can be run on different container platforms, they provide REST and gRCP interfaces, they can be extended with custom models and they can easily be embedded in solutions. While this offering is new, the underlaying functionality has been used and optimized for a long time in IBM offerings like the IBM Watson Assistant and NLU (Natural Language Understanding) SaaS services and IBM Cloud Pak for Data. Via kubectl or oc Kubernetes resources can be deployed. The Watson NLP pod contains the NLP runtime container and potentially multiple init containers. Each init container contains either predefined or custom models.</details>

*Result 3 chunckid or document_id:* 1.2022-10-25-IBM-Helps-Ecosystem-Partners-Accelerate-AI-Adoption-by-Making-it-Easier-to-Embed-and-Scale-AI-Across-Their-Business

<details><summary>Result 3</summary>IBM Helps Ecosystem Partners Accelerate AI Adoption by Making it Easier to Embed and Scale AI Across Their Business. Generally available today, the AI libraries were developed in IBM Research and designed to provide Independent Software Vendors (ISVs) across industries an easily scalable way to build natural language processing, speech to text, and text to speech capabilities into applications across any hybrid, multi cloud environment.</details>


### Model as a Service

*MaaS Model:* google/flan-ul2

*Duration in Milliseconds:* 3560

*Min Tokens:* 1

*Max Tokens:* 300

*Prompt:* IBM Watson NLP (Natural Language Understanding) and Watson Speech containers can be run locally, on-premises or Kubernetes and OpenShift clusters.

This post describes different options how to run and deploy Watson NLP. To set some context, check out the landing page IBM Watson NLP Library for Embed. The Watson NLP containers can be run on different container platforms, they provide REST and gRCP interfaces, they can be extended with custom models and they can easily be embedded in solutions. While this offering is new, the underlaying functionality has been used and optimized for a long time in IBM offerings like the IBM Watson Assistant and NLU (Natural Language Understanding) SaaS services and IBM Cloud Pak for Data. Via kubectl or oc Kubernetes resources can be deployed. The Watson NLP pod contains the NLP runtime container and potentially multiple init containers. Each init container contains either predefined or custom models.

Generally available today, the AI libraries were developed in IBM Research and designed to provide Independent Software Vendors (ISVs) across industries an easily scalable way to build natural language processing, speech to text, and text to speech capabilities into applications across any hybrid, multi cloud environment.

User: Can Watson NLP run as containers on multi cloud environments?
Agent:
